{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import argparse\n",
    "import math\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.multiprocessing as mp\n",
    "import torch.utils.data as data\n",
    "\n",
    "#import utils\n",
    "#import models.builer as builder\n",
    "#import dataloader\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim=128):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "\n",
    "            ####block one#############\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            ####block two#############\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            ####block three#############\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=2, dilation=2),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            ####block four#############\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=2, dilation=2),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            ####block five#############\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(512, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(256, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            ####block six#############\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(32, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            ####linear layers#########\n",
    "            nn.Flatten(),  # Flatten the output of conv layer\n",
    "            nn.Linear(16 * 28 * 28, 512),  # Adjust 512 as needed\n",
    "            nn.Tanh(),\n",
    "            \n",
    "            nn.Linear(512, latent_dim),  # Adjust 128 as needed\n",
    "            nn.Tanh()\n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return x\n",
    "\n",
    "    #def forward(self, x):\n",
    "    #    for layer in self.encoder:\n",
    "    #        x = layer(x)\n",
    "    #        print(f\"Shape after {layer.__class__.__name__}: {x.shape}\")\n",
    "    #    return x\n",
    "    \n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim=128):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.decoder = nn.Sequential(\n",
    "\n",
    "            ###linear layers##############\n",
    "            nn.Linear(latent_dim, 512),\n",
    "            nn.Tanh(),\n",
    "            \n",
    "            nn.Linear(512, 16 * 28 * 28),\n",
    "            nn.Tanh(),\n",
    "            \n",
    "            nn.Unflatten(1, (16, 28, 28)),\n",
    "\n",
    "            ####block six#################\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "\n",
    "            ####block five#################\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "\n",
    "            ####block four#################\n",
    "            #nn.ConvTranspose2d(in_channels=512, out_channels=512, kernel_size=2, stride=2),\n",
    "\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 256, kernel_size=3, stride=1, padding=1),\n",
    "\n",
    "            ####block three#################\n",
    "            nn.ConvTranspose2d(in_channels=256, out_channels=256, kernel_size=2, stride=2),\n",
    "\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 128, kernel_size=3, stride=1, padding=1),\n",
    "\n",
    "            ####block two#################\n",
    "            nn.ConvTranspose2d(in_channels=128, out_channels=128, kernel_size=2, stride=2),\n",
    "\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
    "\n",
    "            ####block one#################\n",
    "            nn.ConvTranspose2d(in_channels=64, out_channels=64, kernel_size=2, stride=2),\n",
    "\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "    #def forward(self, x):\n",
    "    #    for layer in self.decoder:\n",
    "    #        x = layer(x)\n",
    "    #        print(f\"Shape after {layer.__class__.__name__}: {x.shape}\")\n",
    "    #    return x\n",
    "\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, latent_dim=128):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = Encoder(latent_dim)\n",
    "        self.decoder = Decoder(latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passing through Encoder:\n",
      "Shape after Conv2d: torch.Size([1, 64, 224, 224])\n",
      "Shape after BatchNorm2d: torch.Size([1, 64, 224, 224])\n",
      "Shape after ReLU: torch.Size([1, 64, 224, 224])\n",
      "Shape after Conv2d: torch.Size([1, 64, 224, 224])\n",
      "Shape after BatchNorm2d: torch.Size([1, 64, 224, 224])\n",
      "Shape after ReLU: torch.Size([1, 64, 224, 224])\n",
      "Shape after MaxPool2d: torch.Size([1, 64, 112, 112])\n",
      "Shape after Conv2d: torch.Size([1, 128, 112, 112])\n",
      "Shape after BatchNorm2d: torch.Size([1, 128, 112, 112])\n",
      "Shape after ReLU: torch.Size([1, 128, 112, 112])\n",
      "Shape after Conv2d: torch.Size([1, 128, 112, 112])\n",
      "Shape after BatchNorm2d: torch.Size([1, 128, 112, 112])\n",
      "Shape after ReLU: torch.Size([1, 128, 112, 112])\n",
      "Shape after MaxPool2d: torch.Size([1, 128, 56, 56])\n",
      "Shape after Conv2d: torch.Size([1, 256, 56, 56])\n",
      "Shape after BatchNorm2d: torch.Size([1, 256, 56, 56])\n",
      "Shape after ReLU: torch.Size([1, 256, 56, 56])\n",
      "Shape after Conv2d: torch.Size([1, 256, 56, 56])\n",
      "Shape after BatchNorm2d: torch.Size([1, 256, 56, 56])\n",
      "Shape after ReLU: torch.Size([1, 256, 56, 56])\n",
      "Shape after Conv2d: torch.Size([1, 256, 56, 56])\n",
      "Shape after BatchNorm2d: torch.Size([1, 256, 56, 56])\n",
      "Shape after ReLU: torch.Size([1, 256, 56, 56])\n",
      "Shape after Conv2d: torch.Size([1, 256, 56, 56])\n",
      "Shape after BatchNorm2d: torch.Size([1, 256, 56, 56])\n",
      "Shape after ReLU: torch.Size([1, 256, 56, 56])\n",
      "Shape after MaxPool2d: torch.Size([1, 256, 28, 28])\n",
      "Shape after Conv2d: torch.Size([1, 512, 28, 28])\n",
      "Shape after BatchNorm2d: torch.Size([1, 512, 28, 28])\n",
      "Shape after ReLU: torch.Size([1, 512, 28, 28])\n",
      "Shape after Conv2d: torch.Size([1, 512, 28, 28])\n",
      "Shape after BatchNorm2d: torch.Size([1, 512, 28, 28])\n",
      "Shape after ReLU: torch.Size([1, 512, 28, 28])\n",
      "Shape after Conv2d: torch.Size([1, 512, 28, 28])\n",
      "Shape after BatchNorm2d: torch.Size([1, 512, 28, 28])\n",
      "Shape after ReLU: torch.Size([1, 512, 28, 28])\n",
      "Shape after Conv2d: torch.Size([1, 512, 28, 28])\n",
      "Shape after BatchNorm2d: torch.Size([1, 512, 28, 28])\n",
      "Shape after ReLU: torch.Size([1, 512, 28, 28])\n",
      "Shape after Conv2d: torch.Size([1, 512, 28, 28])\n",
      "Shape after BatchNorm2d: torch.Size([1, 512, 28, 28])\n",
      "Shape after ReLU: torch.Size([1, 512, 28, 28])\n",
      "Shape after Conv2d: torch.Size([1, 256, 28, 28])\n",
      "Shape after BatchNorm2d: torch.Size([1, 256, 28, 28])\n",
      "Shape after ReLU: torch.Size([1, 256, 28, 28])\n",
      "Shape after Conv2d: torch.Size([1, 256, 28, 28])\n",
      "Shape after BatchNorm2d: torch.Size([1, 256, 28, 28])\n",
      "Shape after ReLU: torch.Size([1, 256, 28, 28])\n",
      "Shape after Conv2d: torch.Size([1, 128, 28, 28])\n",
      "Shape after BatchNorm2d: torch.Size([1, 128, 28, 28])\n",
      "Shape after ReLU: torch.Size([1, 128, 28, 28])\n",
      "Shape after Conv2d: torch.Size([1, 128, 28, 28])\n",
      "Shape after BatchNorm2d: torch.Size([1, 128, 28, 28])\n",
      "Shape after ReLU: torch.Size([1, 128, 28, 28])\n",
      "Shape after Conv2d: torch.Size([1, 64, 28, 28])\n",
      "Shape after BatchNorm2d: torch.Size([1, 64, 28, 28])\n",
      "Shape after ReLU: torch.Size([1, 64, 28, 28])\n",
      "Shape after Conv2d: torch.Size([1, 64, 28, 28])\n",
      "Shape after BatchNorm2d: torch.Size([1, 64, 28, 28])\n",
      "Shape after ReLU: torch.Size([1, 64, 28, 28])\n",
      "Shape after Conv2d: torch.Size([1, 32, 28, 28])\n",
      "Shape after BatchNorm2d: torch.Size([1, 32, 28, 28])\n",
      "Shape after ReLU: torch.Size([1, 32, 28, 28])\n",
      "Shape after Conv2d: torch.Size([1, 32, 28, 28])\n",
      "Shape after BatchNorm2d: torch.Size([1, 32, 28, 28])\n",
      "Shape after ReLU: torch.Size([1, 32, 28, 28])\n",
      "Shape after Conv2d: torch.Size([1, 16, 28, 28])\n",
      "Shape after BatchNorm2d: torch.Size([1, 16, 28, 28])\n",
      "Shape after ReLU: torch.Size([1, 16, 28, 28])\n",
      "Shape after Flatten: torch.Size([1, 12544])\n",
      "Shape after Linear: torch.Size([1, 512])\n",
      "Shape after Tanh: torch.Size([1, 512])\n",
      "Shape after Linear: torch.Size([1, 128])\n",
      "Shape after Tanh: torch.Size([1, 128])\n",
      "\n",
      "Passing through Decoder:\n",
      "Shape after Linear: torch.Size([1, 512])\n",
      "Shape after Tanh: torch.Size([1, 512])\n",
      "Shape after Linear: torch.Size([1, 12544])\n",
      "Shape after Tanh: torch.Size([1, 12544])\n",
      "Shape after Unflatten: torch.Size([1, 16, 28, 28])\n",
      "Shape after BatchNorm2d: torch.Size([1, 16, 28, 28])\n",
      "Shape after ReLU: torch.Size([1, 16, 28, 28])\n",
      "Shape after Conv2d: torch.Size([1, 32, 28, 28])\n",
      "Shape after BatchNorm2d: torch.Size([1, 32, 28, 28])\n",
      "Shape after ReLU: torch.Size([1, 32, 28, 28])\n",
      "Shape after Conv2d: torch.Size([1, 32, 28, 28])\n",
      "Shape after BatchNorm2d: torch.Size([1, 32, 28, 28])\n",
      "Shape after ReLU: torch.Size([1, 32, 28, 28])\n",
      "Shape after Conv2d: torch.Size([1, 64, 28, 28])\n",
      "Shape after BatchNorm2d: torch.Size([1, 64, 28, 28])\n",
      "Shape after ReLU: torch.Size([1, 64, 28, 28])\n",
      "Shape after Conv2d: torch.Size([1, 64, 28, 28])\n",
      "Shape after BatchNorm2d: torch.Size([1, 64, 28, 28])\n",
      "Shape after ReLU: torch.Size([1, 64, 28, 28])\n",
      "Shape after Conv2d: torch.Size([1, 128, 28, 28])\n",
      "Shape after BatchNorm2d: torch.Size([1, 128, 28, 28])\n",
      "Shape after ReLU: torch.Size([1, 128, 28, 28])\n",
      "Shape after Conv2d: torch.Size([1, 128, 28, 28])\n",
      "Shape after BatchNorm2d: torch.Size([1, 128, 28, 28])\n",
      "Shape after ReLU: torch.Size([1, 128, 28, 28])\n",
      "Shape after Conv2d: torch.Size([1, 256, 28, 28])\n",
      "Shape after BatchNorm2d: torch.Size([1, 256, 28, 28])\n",
      "Shape after ReLU: torch.Size([1, 256, 28, 28])\n",
      "Shape after Conv2d: torch.Size([1, 256, 28, 28])\n",
      "Shape after BatchNorm2d: torch.Size([1, 256, 28, 28])\n",
      "Shape after ReLU: torch.Size([1, 256, 28, 28])\n",
      "Shape after Conv2d: torch.Size([1, 512, 28, 28])\n",
      "Shape after BatchNorm2d: torch.Size([1, 512, 28, 28])\n",
      "Shape after ReLU: torch.Size([1, 512, 28, 28])\n",
      "Shape after Conv2d: torch.Size([1, 512, 28, 28])\n",
      "Shape after BatchNorm2d: torch.Size([1, 512, 28, 28])\n",
      "Shape after ReLU: torch.Size([1, 512, 28, 28])\n",
      "Shape after Conv2d: torch.Size([1, 512, 28, 28])\n",
      "Shape after BatchNorm2d: torch.Size([1, 512, 28, 28])\n",
      "Shape after ReLU: torch.Size([1, 512, 28, 28])\n",
      "Shape after Conv2d: torch.Size([1, 512, 28, 28])\n",
      "Shape after BatchNorm2d: torch.Size([1, 512, 28, 28])\n",
      "Shape after ReLU: torch.Size([1, 512, 28, 28])\n",
      "Shape after Conv2d: torch.Size([1, 512, 28, 28])\n",
      "Shape after BatchNorm2d: torch.Size([1, 512, 28, 28])\n",
      "Shape after ReLU: torch.Size([1, 512, 28, 28])\n",
      "Shape after Conv2d: torch.Size([1, 256, 28, 28])\n",
      "Shape after ConvTranspose2d: torch.Size([1, 256, 56, 56])\n",
      "Shape after BatchNorm2d: torch.Size([1, 256, 56, 56])\n",
      "Shape after ReLU: torch.Size([1, 256, 56, 56])\n",
      "Shape after Conv2d: torch.Size([1, 256, 56, 56])\n",
      "Shape after BatchNorm2d: torch.Size([1, 256, 56, 56])\n",
      "Shape after ReLU: torch.Size([1, 256, 56, 56])\n",
      "Shape after Conv2d: torch.Size([1, 256, 56, 56])\n",
      "Shape after BatchNorm2d: torch.Size([1, 256, 56, 56])\n",
      "Shape after ReLU: torch.Size([1, 256, 56, 56])\n",
      "Shape after Conv2d: torch.Size([1, 256, 56, 56])\n",
      "Shape after BatchNorm2d: torch.Size([1, 256, 56, 56])\n",
      "Shape after ReLU: torch.Size([1, 256, 56, 56])\n",
      "Shape after Conv2d: torch.Size([1, 128, 56, 56])\n",
      "Shape after ConvTranspose2d: torch.Size([1, 128, 112, 112])\n",
      "Shape after BatchNorm2d: torch.Size([1, 128, 112, 112])\n",
      "Shape after ReLU: torch.Size([1, 128, 112, 112])\n",
      "Shape after Conv2d: torch.Size([1, 128, 112, 112])\n",
      "Shape after BatchNorm2d: torch.Size([1, 128, 112, 112])\n",
      "Shape after ReLU: torch.Size([1, 128, 112, 112])\n",
      "Shape after Conv2d: torch.Size([1, 64, 112, 112])\n",
      "Shape after ConvTranspose2d: torch.Size([1, 64, 224, 224])\n",
      "Shape after BatchNorm2d: torch.Size([1, 64, 224, 224])\n",
      "Shape after ReLU: torch.Size([1, 64, 224, 224])\n",
      "Shape after Conv2d: torch.Size([1, 64, 224, 224])\n",
      "Shape after BatchNorm2d: torch.Size([1, 64, 224, 224])\n",
      "Shape after ReLU: torch.Size([1, 64, 224, 224])\n",
      "Shape after Conv2d: torch.Size([1, 3, 224, 224])\n",
      "Shape after Sigmoid: torch.Size([1, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Instantiate the autoencoder\n",
    "    autoencoder = Autoencoder(latent_dim=128)\n",
    "    \n",
    "    # Create a random input tensor (batch_size=1, channels=3, height=224, width=224)\n",
    "    input_tensor = torch.rand(1, 3, 224, 224)\n",
    "    \n",
    "    # Pass the tensor through the encoder\n",
    "    print(\"Passing through Encoder:\")\n",
    "    x = input_tensor\n",
    "    for layer in autoencoder.encoder.encoder:\n",
    "        x = layer(x)\n",
    "        print(f\"Shape after {layer.__class__.__name__}: {x.shape}\")\n",
    "    \n",
    "    # Pass the tensor through the decoder\n",
    "    print(\"\\nPassing through Decoder:\")\n",
    "    for layer in autoencoder.decoder.decoder:\n",
    "        x = layer(x)\n",
    "        print(f\"Shape after {layer.__class__.__name__}: {x.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
